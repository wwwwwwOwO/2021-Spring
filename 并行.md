#### 第一讲：并行计算概览，内容要点：

##### 1、 什么是并行计算？

> 并行计算可以简单定义为**同时利用多个计算资源解决一个计算问题**
>
> + 程序运行在多个CPU上；
> + 一个问题被分解成离散可并发解决的小部分； 
> + 每一小部分被进一步分解成一组指令序列； 
> + 每一部分的指令在不同的CPU上同时执行；
> + 需要一个**全局的控制和协调机制**；  

##### 2、 并行计算有哪些优势？

> + 在自然界，很多复杂的、交叉发生的事件是同时发生的，但是又在同一个时间序列中；
>
>   与串行计算相比，并行计算**更擅长建模、模拟、理解真实复杂的现象**；  
>
> + 节省时间和花费  
>
> + 解决更大／更复杂问题  
>
> + 实现并发处理  
>
> + 利用非本地资源  
>
> + 更好地发挥底层并行硬件  

##### 3、 并行计算的主要用途？

> + 科学和工程计算  
> + 工业和商业应用  
> + 全球范围的应用  

##### 4、 并行计算的主要推动力是什么？

> + 应用发展趋势  
>
>   + 在硬件可达到的性能与应用对性能的需求之间存在正反馈  
>   + 大量设备、用户、内容涌现  
>   + 大数据场景、云计算的兴起  
>
> + 架构发展趋势  
>
>   迄今为止， CPU架构技术经历了四代即：电子管（ Tube）、晶体管（ Transistor） 、 集
>   成电路（ IC）和大规模集成电路（ VLSI），这里只关注VLSI。
>
>   VLSI最的特色是在于对并行化的利用，不同的VLSI时代具有不同的并行粒度：
>
>   + 1985年之前： bit水平的并行，从4bit->8 bit->16bit （数据通路）
>     + 32bit后并行化速度放慢?
>     + 最近几年64bit才被广泛使用， 128bit还很遥远，（非性能限制）
>     + 32bit并行技术的应用导致了计算机性能的显著提高
>
>   + 80年代到90年代：指令水平的并行  
>     + 流水线、简单指令集、先进的编译技术（ RISC）
>     + 片上缓存（ caches）和功能部件 =>超变量执行
>     + 更复杂控制机制：乱序执行、推测、预测，用于控制转换和延迟问题；
>   + 线程水平的并行
>     + 现代并行计算的主要方式：线程并行。
>
> 
>
> + 1990年之前的解决方式：
>   + 增加时钟频率（扩频）
>     + 深化流水线（采用更多／更短的流水阶段）
>     + 芯片的工作温度会过高
>     
>   + 推测超标量（ Speculative Superscalar, SS）
>     
>     多条指令同时执行（指令级的并行， ILP）：
>
>     + 硬件自动找出串行程序中的能够同时执行的独立指令集合；
>     + 硬件预测分支指令；
>       在分支指令实际发生之前先推测执行；
>
>   局限：最终出现“收益下降（ diminishing returns）”
>   **这种解决方法的优点：程序员并不需要知道这些过程的细节**
>
> + 2000年之后的解决方式：
>
>   + 时钟频率很难增加；
>   + SS触到天花板出现“收益下降”；
>   + **利用额外的额外的晶体管在芯片上构建更多／更简单的处理器**


##### 5、 并行计算的粒度？

> bit、指令、函数、线程、进程
>
> 集群：多个单独的计算机通过网络连接起来形成计算集群  

##### 6、 并行计算的难点？

> + **粒度** 函数级并行、线程级并行还是进程级并行  
> + **局部性** 并行化后是否能够利用局部数据等  
> + **负载均衡** 不同线程、不同 core之间的负载分布  
> + **协作与同步**  
> + **性能模型**  所有这些难点让并行编程要比串行编程复杂得多  

##### 7、 Amdahl’s law?

> $Speedup=\frac{1}{(1-p)+p/n}$



#### 第二讲：并行架构，内容要点：

1、 Flynn’s 并行架构分类？

> SISD、SIMD、MIMD 

2、 什么是 pipeline?

> ![image-20220116180212531](C:\Users\14637\AppData\Roaming\Typora\typora-user-images\image-20220116180212531.png)

3、 有哪些形式的指令级并行？

> 流水线和多发射
>
> VLIW：Let compiler specify which operations can run in parallel  
>
> Vector Processing: Specify groups of similar (independent) operations  
>
> Out of Order Execution (OOO): Allow long operations to happen  

4、 什么是 Pthreads？

5、 内存局部性原则有哪些？

6、 内存分层？

7、 Caches 在内存分层结构中的重要作用

8、 新型存储系统的构成？

> 

9、 什么是并行架构？

>A parallel computer is a collection of processing elements that cooperate to solve large problems fast Some broad issues  

10、 MIMD 的并行架构包括哪些实现类型？

> ![image-20220116183656029](C:\Users\14637\AppData\Roaming\Typora\typora-user-images\image-20220116183656029.png)

11、 MPP 架构的典型例子及主要构成？

> ![image-20220116184120422](C:\Users\14637\AppData\Roaming\Typora\typora-user-images\image-20220116184120422.png)

#### 第三讲： 并行编程模型，内容要点：

1、 什么是并行编程模型？

> ![image-20220116185001883](C:\Users\14637\AppData\Roaming\Typora\typora-user-images\image-20220116185001883.png)
>
> +  What programmer uses in coding applications
> + Specifies communication and synchronization  

2、 并行编程模型的主要包括哪些类型？主要特点是什么？

> + Multiprogramming: no communication or synch. at program level
> + Shared address space: like bulletin board
> + Message passing: like letters or phone calls, explicit point to point
> + Data parallel: more strict, global actions on data
>   \- Implemented with shared address space or message passing  

3、 并行编程模型主要包括哪几部分？

> ![image-20220116190627520](C:\Users\14637\AppData\Roaming\Typora\typora-user-images\image-20220116190627520.png)

4、 共享内存模型有哪些实现？

> Pthread、OpenMP、OpenCL

5、 造成并行编程模型不能达到理想加速比的原因？

> 可并行化部分

6、 任务（Task）和线程（Thread）之间的关系？

> 一个线程执行一个Task

7、 什么是线程竞争？如何解决？

> 锁、信号量

#### 第四讲：并行编程方法论，内容要点：

1、 什么是增量式并行化？

> 研究一个顺序程序（或代码段）
> 寻找并行的瓶颈和机会
> 尽量让所有处理器忙于做有用的工作

2、 Culler 并行设计流程？

> ![image-20220116202418638](C:\Users\14637\AppData\Roaming\Typora\typora-user-images\image-20220116202418638.png)
>
> ![image-20220116202527283](C:\Users\14637\AppData\Roaming\Typora\typora-user-images\image-20220116202527283.png)
>
> ![image-20220116202552296](C:\Users\14637\AppData\Roaming\Typora\typora-user-images\image-20220116202552296.png)

3、 Foster 并行设计流程？

> 划分、通信、归并、部署

4、 按数据分解和按任务分解的特点？

5、 并行任务分解过程中应该注意的问题有哪些？

6、 整合的意义是什么？

7、 Mapping（映射）如何决策？

> ![image-20220116205110716](C:\Users\14637\AppData\Roaming\Typora\typora-user-images\image-20220116205110716.png)

8、 熟悉一些并行设计的例子。



第五讲：OpenMP 并行编程模型，内容要点：
1、 什么是 OpenMP？

> 开放多处理

2、 OpenMP 的主要特点是什么？

> 优势
>
> + Incremental parallelization & sequential equivalence
> + Well-suited for domain decompositions
> + Available on *nix and Windows
>
> Weaknesses
>
> + Not well-tailored for functional decompositions
> + Compilers do not have to check for such errors as deadlocks and race conditions  

3、 熟悉 OpenMP 的关键指令。

> section no wait critical single atomic first/last private 

4、 熟悉 OpenMP 关键指令的执行过程。



第六讲：OpenMP 中的竞争和同步，内容要点：
1、 OpenMP 中为了保证程序正确性而采用哪些机制？

> barrier、互斥、memory fense

2、 什么是同步，同步的主要方式有哪些？

> - critical
> - atomic
> - barrier
> - ordered
> - flush
> - locks

3、 OpenMP Barrier 的执行原理。

> 

4、 OpenMP 中竞争的例子。

5、 OpenMP 中避免数据竞争的方式有哪些？

6、 OpenMP Critical 与 Atomic 的主要区别是什么？

> Critical锁定块、Atomic锁定指令

第七讲：OpenMP 性能优化，内容要点：
1、 什么是计算效率？

2、 调整后的 Amdahl 定律如何理解？

> ![image-20220117165220331](C:\Users\14637\AppData\Roaming\Typora\typora-user-images\image-20220117165220331.png)

3、 OpenMP 中 Loop 调度的几种方式，执行过程。

4、 OpenMP 中 Loop 转换的方式包括哪几种？熟练掌握。

> - Loop fission 拆分loop
> - Loop fusion 合并loop
> - Loop exchange  

第八讲：MPI 编程模型，内容要点：
1、 什么是 MPI 编程模型？

> 分布式存储、消息传递

2、 消息传递性并行编程模型的主要原则是什么？

> 异步和loose同步

3、 MPI 中的几种 Send 和 Receive 操作包括原理和应用场景。

![image-20220117175746699](C:\Users\14637\AppData\Roaming\Typora\typora-user-images\image-20220117175746699.png)

![image-20220117180010653](C:\Users\14637\AppData\Roaming\Typora\typora-user-images\image-20220117180010653.png)4、 MPI 中的关键编程接口。

> 6个

5、 什么是通信子？

> 表示一个通信域，通信域内的进程可以互相通信，否则不能通信

6、 MPI 中解决死锁的方式有哪些？

7、 MPI 中的集群通信操作有哪些？原理是什么？

> scatter、bcast 



#### 第九讲：MPI 与 OpenMP 联合编程，内容要点：

1、 如何利用 MPI 实现 Matrix-vector 乘积？不同实现的特点是什么？

2、 MPI 和 OpenMP 结合的优势是什么？

> ![image-20220117183541721](C:\Users\14637\AppData\Roaming\Typora\typora-user-images\image-20220117183541721.png)

3、 如何利用 MPI+OpenMP 实现高斯消元？
第十讲：GPGPU、CUDA 和 OpenCL 编程模型，内容要点：
1、 CUDA 的含义是什么？

2、 CUDA 的设计目标是什么？与传统的多线程设计有什么不同？

> 为跨各种处理器的数据并行编程提供内在可扩展的环境
>
> ![image-20220117190042079](C:\Users\14637\AppData\Roaming\Typora\typora-user-images\image-20220117190042079.png)
>
> ![image-20220117190302599](C:\Users\14637\AppData\Roaming\Typora\typora-user-images\image-20220117190302599.png)
>
> ![image-20220117190817324](C:\Users\14637\AppData\Roaming\Typora\typora-user-images\image-20220117190817324.png)

3、 什么是 CUDA kernel?

> Warp![image-20220117185925516](C:\Users\14637\AppData\Roaming\Typora\typora-user-images\image-20220117185925516.png)
>
> kernel-可独立执行的函数  

4、 CUDA 的编程样例。

5、 CUDA 的线程分层结构。

> Grid、Block、Thread

6、 CUDA 的内存分层结构。

> Local Shared Global

7、 CUDA 中的内存访问冲突。

> 

8、 OpenCL 运行时编译过程。

> ![image-20220117194229486](C:\Users\14637\AppData\Roaming\Typora\typora-user-images\image-20220117194229486.png)
>
> ![image-20220117194852312](C:\Users\14637\AppData\Roaming\Typora\typora-user-images\image-20220117194852312.png)

第十一讲：MapReduce 并行编程模型，内容要点：

1、 为什么会产生 MapReduce 并行编程模型？

> 大数据时代的需要

2、 MapReduce 与其他并行编程模型如 MPI 等的主要区别是什么？

> 粒度更大、数据量更大、单位是集群

3、 MapReduce 的主要流程是什么？

> Job、Task、Task Attempt
>
> ![image-20220117122712511](C:\Users\14637\AppData\Roaming\Typora\typora-user-images\image-20220117122712511.png)

4、 MapReduce 的简单实现。如 Hello World 例子。

> ![image-20220117122933441](C:\Users\14637\AppData\Roaming\Typora\typora-user-images\image-20220117122933441.png)
>
> ![image-20220117123011650](C:\Users\14637\AppData\Roaming\Typora\typora-user-images\image-20220117123011650.png)
>
> ![image-20220117123031722](C:\Users\14637\AppData\Roaming\Typora\typora-user-images\image-20220117123031722.png)
>
> + Partitions input data
>   Partition and distribute data amongst different nodes
> + Schedules executions across a set of machines
>   Yarn – (Resource Manager), FIFO. (Many Research work)
> + Handles machine failure
>   Reschedule tasks when the machine fails.
> + Manages interprocess communication  

5、 MapReduce 具有哪些容错措施？

> Master detects worker failures
>
> + Re-executes completed & in-progress map() tasks
> + Re-executes in-progress reduce() tasks
>
> Master notices particular input key/values cause crashes in map(), and skips those values on re-execution
>
> + Effect: Can work around bugs in third-party libraries!

6、 MapReduce 存在哪些优化点？

> + No reduce can start until map is complete
> + A single slow disk controller can rate-limit the whole process
> + Master redundantly executes “slow-moving” map tasks; uses results of first copy to finish
> + “Combiner” functions can run on same machine as a mapper
> + Causes a mini-reduce phase to occur before the real reduce phase, to save bandwidth
>
> local reduce

7、 MapReduce 可以解决的问题有哪些？

> ![image-20220117204254892](C:\Users\14637\AppData\Roaming\Typora\typora-user-images\image-20220117204254892.png)

##### 第十二讲：基于 Spark 的分布式计算，内容要点：

1、 Spark 与 Hadoop 的区别和联系。

> 一、应用场景不同
>
> Hadoop和Spark两者都是大数据框架，但是各自应用场景是不同的。Hadoop是一个分布式数据存储架构，它将巨大的数据集分派到一个由普通计算机组成的集群中的多个节点进行存储，降低了硬件的成本。Spark是那么一个专门用来对那些分布式存储的大数据进行处理的工具，它要借助hdfs的数据存储。
>
> 二、处理速度不同
>
> hadoop的MapReduce是分步对数据进行处理的，从磁盘中读取数据，进行一次处理，将结果写到磁盘，然后在从磁盘中读取更新后的数据，再次进行的处理，最后再将结果存入磁盘，这存取磁盘的过程会影响处理速度。spark从磁盘中读取数据，把中间数据放到内存中，，完成所有必须的分析处理，将结果写回集群，所以spark更快。
>
> 三、容错性不同
>
> Hadoop将每次处理后的数据都写入到磁盘上，基本谈不上断电或者出错数据丢失的情况。Spark的数据对象存储在弹性分布式数据集 RDD，RDD是分布在一组节点中的只读对象集合，如果数据集一部分丢失，则可以根据于数据衍生过程对它们进行重建。而且RDD 计算时可以通过 CheckPoint 来实现容错。
>
> 四、Hadoop是一个由Apache基金会所开发的分布式系统基础架构。 Hadoop实现了一个分布式文件系统HDFS。HDFS有高容错性的特点，并且设计用来部署在低廉的硬件上；而且它提供高吞吐量来访问应用程序的数据，适合那些有着超大数据集的应用程序。Hadoop的框架最核心的设计就是：HDFS和MapReduce。HDFS为海量的数据提供了存储，而MapReduce则为海量的数据提供了计算
>
> Hadoop 以一种可靠、高效、可伸缩的方式进行数据处理。
>
> 可靠性: Hadoop将数据存储在多个备份，Hadoop提供高吞吐量来访问应用程序的数据。
>
> 高扩展性： Hadoop是在可用的计算机集簇间分配数据并完成计算任务的，这些集簇可以方便地扩展到数以千计的节点中。
>
> 高效性： Hadoop以并行的方式工作，通过并行处理加快处理速度。
>
> 高容错性： Hadoop能够自动保存数据的多个副本，并且能够自动将失败的任务重新分配。
>
> 低成本： Hadoop能够部署在低廉的（low-cost）硬件上。
>
> 五、Spark 是专为大规模数据处理而设计的快速通用的计算引擎。Spark拥有Hadoop MapReduce所具有的优点，Spark在Job中间输出结果可以保存在内存中，从而不再需要读写HDFS，因此Spark性能以及运算速度高于MapReduce。
>
> 计算速度快: 因为spark从磁盘中读取数据，把中间数据放到内存中，，完成所有必须的分析处理，将结果写回集群，所以spark更快。
>
> Spark 提供了大量的库: 包括Spark Core、Spark SQL、Spark Streaming、MLlib、GraphX。
>
> 支持多种资源管理器: Spark 支持 Hadoop YARN，及其自带的独立集群管理器
>
> 操作简单: 高级 API 剥离了对集群本身的关注，Spark 应用开发者可以专注于应用所要做的计算本身
>
> 六、spark与hadoop联系
>
> Hadoop提供分布式数据存储功能HDFS，还提供了用于数据处理的MapReduce。 MapReduce是可以不依靠spark数据的处理的。当然spark也可以不依靠HDFS进行运作，它可以依靠其它的分布式文件系统。但是两者完全可以结合在一起，hadoop提供分布式 集群和分布式 文件系统，spark可以依附在hadoop的HDFS代替MapReduce弥补MapReduce计算能力不足的问题。
>
> 总结一句话：spark在hadoop肩膀上可以让大数据跑得更快

2、 传统 MapReduce 的主要缺点是什么？

> 多传递算法低效率、没有高效的原语来进行数据共享，冗余和磁盘存储速度慢

3、 Spark 中的 RDD 如何理解？

> RDD(Resilient Distributed Datasets)  ，弹性分布式数据集， 是分布式内存的一个抽象概念，RDD提供了一种高度受限的共享内存模型，即RDD是只读的记录分区的集合，只能通过在其他RDD执行确定的转换操作（如map、join和group by）而创建，然而这些限制使得实现容错的开销很低。对开发者而言，RDD可以看作是Spark的一个对象，它本身运行于内存中，如读文件是一个RDD，对文件计算是一个RDD，结果集也是一个RDD ，不同的分片、 数据之间的依赖 、key-value类型的map数据都可以看做RDD。
>
> 弹性分布式数据集（RDD，Resilient Distributed Datasets），它具备像MapReduce等数据流模型的容错特性，并且允许开发人员在大型集群上执行基于内存的计算。现有的数据流系统对两种应用的处理并不高效：一是迭代式算法，这在图应用和机器学习领域很常见；二是交互式数据挖掘工具。这两种情况下，将数据保存在内存中能够极大地提高性能。为了有效地实现容错，RDD提供了一种高度受限的共享内存，即RDD是只读的，并且只能通过其他RDD上的批量操作来创建。尽管如此，RDD仍然足以表示很多类型的计算，包括MapReduce和专用的迭代编程模型（如Pregel）等  。
> RDD是只读的、分区记录的集合。RDD只能基于在稳定物理存储中的数据集和其他已有的RDD上执行确定性操作来创建。这些确定性操作称之为转换，如map、filter、groupBy、join（转换不是程开发人员在RDD上执行的操作） 。
> RDD不需要物化。RDD含有如何从其他RDD衍生（即计算）出本RDD的相关信息（即Lineage），据此可以从物理存储的数据计算出相应的RDD分区  。
> RDD作为数据结构，本质上是一个只读的分区记录集合。一个RDD可以包含多个分区，每个分区就是一个dataset片段。RDD可以相互依赖。如果RDD的每个分区最多只能被一个Child RDD的一个分区使用，则称之为narrow dependency；若多个Child RDD分区都可以依赖，则称之为wide dependency。不同的操作依据其特性，可能会产生不同的依赖。例如map操作会产生narrow dependency，而join操作则产生wide dependency。

4、 Spark 样例程序。
第十三讲：离散搜索与负载均衡，内容要点：
1、 深度优先搜索的主要流程。

> 深度优先遍历图的方法是，从图中某顶点v出发：
> （1）访问顶点v；
> （2）依次从v的未被访问的邻接点出发，对图进行深度优先遍历；直至图中和v有路径相通的顶点都被访问；
> （3）若此时图中尚有顶点未被访问，则从一个未被访问的顶点出发，重新进行深度优先遍历，直到图中所有顶点均被访问过为止。　当然，当人们刚刚掌握深度优先搜索的时候常常用它来走迷宫.事实上我们还有别的方法，那就是广度优先搜索(BFS).
>
> ![image-20220117205932692](C:\Users\14637\AppData\Roaming\Typora\typora-user-images\image-20220117205932692.png)

2、 深度优先搜索的复杂度。

> **时间复杂度O(n)，空间复杂度O(n)。**
>
> ![image-20220117210046012](C:\Users\14637\AppData\Roaming\Typora\typora-user-images\image-20220117210046012.png)

3、 并行深度优先搜索的主要设计思想。

> ![image-20220117210120955](C:\Users\14637\AppData\Roaming\Typora\typora-user-images\image-20220117210120955.png)
>
> ![image-20220117210155972](C:\Users\14637\AppData\Roaming\Typora\typora-user-images\image-20220117210155972.png)
>
> ![image-20220117210235239](C:\Users\14637\AppData\Roaming\Typora\typora-user-images\image-20220117210235239.png)
>
> ![image-20220117210250668](C:\Users\14637\AppData\Roaming\Typora\typora-user-images\image-20220117210250668.png)
>
> ![image-20220117210527574](C:\Users\14637\AppData\Roaming\Typora\typora-user-images\image-20220117210527574.png)

4、 动态负载均衡的三种方式，以及每种方式的额外开销复杂度。

> ![image-20220117210755475](C:\Users\14637\AppData\Roaming\Typora\typora-user-images\image-20220117210755475.png)
>
> ![image-20220117210829545](C:\Users\14637\AppData\Roaming\Typora\typora-user-images\image-20220117210829545.png)
>
>  ![*](C:\Users\14637\AppData\Roaming\Typora\typora-user-images\image-20220117220905970.png)
>
> ![image-20220117221210001](C:\Users\14637\AppData\Roaming\Typora\typora-user-images\image-20220117221210001.png)

5、 最优搜索的处理过程。

6、 并行最优搜索的主要思想和实现方式。
7、 什么是加速比异常？主要分为哪几类？
第十四讲：并行图算法
1、 最小生成树的串行和并行算法原理；
2、 Prim 并行算法的复杂度；
3、 单源最短路径算法的原理；
4、 单源最短路径算法的并行算法的复杂度；
5、 基于 Dijkstra 的并行 All-pair 最短路径算法的复杂度；
6、 Floyd 并行算法的复杂度；
第十五讲：性能优化之一（任务分派和调度），内容要点：
1、 负载均衡主要有哪些方式？分别有什么特点？

2、 静态、动态负

载均衡适用的场景是什么？
3、 如何选择任务的粒度？
4、 Cilk_spawn 的原理是什么？
5、 Cilk_sync 的原理是什么？
6、 Cilk_spawn 的调度方式有哪些？各自有什么特点？
7、 Cilk_spawn 中任务在不同线程之间 steal 的过程。
8、 Cilk_sync 的几种实现方式。
第十六讲：性能优化之一（局部性、通行和竞争），内容要点：
1、 吞吐量和延迟的定义；
2、 提高程序吞吐有哪些方法？
3、 通信时间和通信代价的定义；
4、 什么是人为通信？什么是天然通信？结合具体的例子说明
5、 减少通信的方法有哪些？
6、 减少竞争的方法有哪些？  
